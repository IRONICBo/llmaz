# Examples

We provide a bunch of examples to serve large language models, whether via inference `Playground` or inference `Service`.

## Table of Contents

### Deploy models via Huggingface

Deploy a small [model](./huggingface/model.yaml) hosted in Huggingface, see [example](./huggingface/playground.yaml). Because model is of a small size, the loading time is acceptable.
