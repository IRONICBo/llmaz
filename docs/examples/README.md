# Examples

We provide a bunch of examples to serve large language models, whether via inference `Playground` or inference `Service`.

## Table of Contents

### Deploy models via Huggingface

Deploy a small [model](./huggingface/model.yaml) hosted in Huggingface, see the [example](./huggingface/playground.yaml) here. Because the model is of a small size, the loading time is acceptable.
