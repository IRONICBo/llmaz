apiVersion: inference.llmaz.io/v1alpha1
kind: Playground
metadata:
  name: qwen2-0--5b-hpa
spec:
  replicas: 1
  modelClaim:
    modelName: qwen2-0--5b-gguf
  backendRuntimeConfig:
    backendName: llamacpp
    configName: default
    args:
      - -fa # use flash attention
  elasticConfig:
    minReplicas: 1
    maxReplicas: 3
    scaleTrigger:
      hpa:
        metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                averageUtilization: 50
                type: Utilization
