apiVersion: inference.llmaz.io/v1alpha1
kind: Playground
metadata:
  name: llama3-405b-instruct
spec:
  replicas: 1
  modelClaim:
    modelName: llama3-405b-instruct
    inferenceFlavorClaims:
      - a100-80gb # actually no need to specify this since we have only one flavor
  backendRuntimeConfig:
    resources:
      requests:
        cpu: 4
        memory: 8Gi
      limits:
        cpu: 4
        memory: 16Gi
