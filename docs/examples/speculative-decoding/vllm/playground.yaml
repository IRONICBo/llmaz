apiVersion: inference.llmaz.io/v1alpha1
kind: Playground
metadata:
  name: vllm-speculator
spec:
  replicas: 1
  modelClaims:
    models:
    - name: opt-6--7b # the target model
      role: main
    - name: opt-125m  # the draft model
      role: draft
  backendRuntimeConfig:
    resources:
      limits:
        cpu: 8
        memory: "16Gi"
